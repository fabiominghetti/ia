{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "name": "Trilha 6 - Análise de Sentimentos - Naive Bayes",
      "provenance": [],
      "collapsed_sections": [
        "PkJDxkeJtkqp",
        "GAbQXJsqHo5v",
        "MHHaMIwzHqxL"
      ],
      "include_colab_link": true
    },
    "interpreter": {
      "hash": "54999d387da01ac009adc1c3ff01d1799bb96e6f581187d9006fa4c4da7ed267"
    },
    "kernelspec": {
      "display_name": "Python 3.9.6 64-bit",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fabiominghetti/ia/blob/main/%5BRIWRS%5D_6_An%C3%A1lise_de_Sentimentos_Naive_Bayes-Original.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQ2sbLzPFtR6"
      },
      "source": [
        "# Carregar as bibliotecas e dados"
      ],
      "id": "WQ2sbLzPFtR6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jy3kwQPwFtSC"
      },
      "source": [
        "## Bibliotecas"
      ],
      "id": "jy3kwQPwFtSC"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkJDxkeJtkqp"
      },
      "source": [
        "### Instalações via PIP"
      ],
      "id": "PkJDxkeJtkqp"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OaTt7lUTF8-n",
        "outputId": "d38d2d4c-59f9-4da4-d7df-ff7ed3f3074e"
      },
      "source": [
        "!pip install unidecode\n",
        "!pip install fractions\n",
        "!pip install googletrans\n",
        "!pip install ibm_watson\n",
        "!pip install ibm_cloud_sdk_core\n",
        "!pip install dotenv\n"
      ],
      "id": "OaTt7lUTF8-n",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.4-py3-none-any.whl (235 kB)\n",
            "\u001b[K     |████████████████████████████████| 235 kB 5.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.3.4\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement fractions (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for fractions\u001b[0m\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting googletrans\n",
            "  Downloading googletrans-3.0.0.tar.gz (17 kB)\n",
            "Collecting httpx==0.13.3\n",
            "  Downloading httpx-0.13.3-py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 985 kB/s \n",
            "\u001b[?25hCollecting httpcore==0.9.*\n",
            "  Downloading httpcore-0.9.1-py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 960 kB/s \n",
            "\u001b[?25hCollecting rfc3986<2,>=1.3\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting sniffio\n",
            "  Downloading sniffio-1.2.0-py3-none-any.whl (10 kB)\n",
            "Collecting hstspreload\n",
            "  Downloading hstspreload-2021.12.1-py3-none-any.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 11.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna==2.* in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans) (2.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans) (2022.5.18.1)\n",
            "Requirement already satisfied: chardet==3.* in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans) (3.0.4)\n",
            "Collecting h2==3.*\n",
            "  Downloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n",
            "\u001b[K     |████████████████████████████████| 65 kB 2.4 MB/s \n",
            "\u001b[?25hCollecting h11<0.10,>=0.8\n",
            "  Downloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 995 kB/s \n",
            "\u001b[?25hCollecting hpack<4,>=3.0\n",
            "  Downloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n",
            "Collecting hyperframe<6,>=5.2.0\n",
            "  Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n",
            "Building wheels for collected packages: googletrans\n",
            "  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for googletrans: filename=googletrans-3.0.0-py3-none-any.whl size=15735 sha256=00a2c25495ad38245629985342ff8694d237d8dd6f09998e28c93c8e6b13a752\n",
            "  Stored in directory: /root/.cache/pip/wheels/20/da/eb/a54579056f265eede0417df537dd56d3df5b9eb2b25df0003d\n",
            "Successfully built googletrans\n",
            "Installing collected packages: hyperframe, hpack, sniffio, h2, h11, rfc3986, httpcore, hstspreload, httpx, googletrans\n",
            "Successfully installed googletrans-3.0.0 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2021.12.1 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 rfc3986-1.5.0 sniffio-1.2.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ibm_watson\n",
            "  Downloading ibm-watson-6.0.0.tar.gz (338 kB)\n",
            "\u001b[K     |████████████████████████████████| 338 kB 5.6 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from ibm_watson) (2.23.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.7/dist-packages (from ibm_watson) (2.8.2)\n",
            "Collecting websocket-client==1.1.0\n",
            "  Downloading websocket_client-1.1.0-py2.py3-none-any.whl (68 kB)\n",
            "\u001b[K     |████████████████████████████████| 68 kB 5.5 MB/s \n",
            "\u001b[?25hCollecting ibm-cloud-sdk-core==3.*,>=3.3.6\n",
            "  Downloading ibm-cloud-sdk-core-3.15.1.tar.gz (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 5.2 MB/s \n",
            "\u001b[?25hCollecting requests<3.0,>=2.0\n",
            "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.5 MB/s \n",
            "\u001b[?25hCollecting urllib3<2.0.0,>=1.26.0\n",
            "  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 13.9 MB/s \n",
            "\u001b[?25hCollecting PyJWT<3.0.0,>=2.0.1\n",
            "  Downloading PyJWT-2.4.0-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.5.3->ibm_watson) (1.15.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0,>=2.0->ibm_watson) (2.10)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3.0,>=2.0->ibm_watson) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0,>=2.0->ibm_watson) (2022.5.18.1)\n",
            "Building wheels for collected packages: ibm-watson, ibm-cloud-sdk-core\n",
            "  Building wheel for ibm-watson (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ibm-watson: filename=ibm_watson-6.0.0-py3-none-any.whl size=336807 sha256=5f43d99411aab2a4e3fde8f0b4e906a65f633093e04421d3525be1f31877e642\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/de/dd/1002a4fdfeed1322ccffb20b0a12e00afbeeee8df4a86769d7\n",
            "  Building wheel for ibm-cloud-sdk-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ibm-cloud-sdk-core: filename=ibm_cloud_sdk_core-3.15.1-py3-none-any.whl size=83648 sha256=941223a3ccc4f0f5756630392cdb4c98e71adf2a8935d47a1f6d0a36e011d89a\n",
            "  Stored in directory: /root/.cache/pip/wheels/ba/7a/ac/408ba6a1438ea293164dbf26483b13a72165894a31e914b5e6\n",
            "Successfully built ibm-watson ibm-cloud-sdk-core\n",
            "Installing collected packages: urllib3, requests, PyJWT, websocket-client, ibm-cloud-sdk-core, ibm-watson\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed PyJWT-2.4.0 ibm-cloud-sdk-core-3.15.1 ibm-watson-6.0.0 requests-2.27.1 urllib3-1.26.9 websocket-client-1.1.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ibm_cloud_sdk_core in /usr/local/lib/python3.7/dist-packages (3.15.1)\n",
            "Requirement already satisfied: PyJWT<3.0.0,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from ibm_cloud_sdk_core) (2.4.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.5.3 in /usr/local/lib/python3.7/dist-packages (from ibm_cloud_sdk_core) (2.8.2)\n",
            "Requirement already satisfied: urllib3<2.0.0,>=1.26.0 in /usr/local/lib/python3.7/dist-packages (from ibm_cloud_sdk_core) (1.26.9)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.26.0 in /usr/local/lib/python3.7/dist-packages (from ibm_cloud_sdk_core) (2.27.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.5.3->ibm_cloud_sdk_core) (1.15.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.26.0->ibm_cloud_sdk_core) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.26.0->ibm_cloud_sdk_core) (2022.5.18.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.26.0->ibm_cloud_sdk_core) (2.10)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting dotenv\n",
            "  Downloading dotenv-0.0.5.tar.gz (2.4 kB)\n",
            "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/e2/46/3754073706e31670eed18bfa8a879305b56a471db15f20523c2427b10078/dotenv-0.0.5.tar.gz#sha256=b58d2ab3f83dbd4f8a362b21158a606bee87317a9444485566b3c8f0af847091 (from https://pypi.org/simple/dotenv/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
            "  Downloading dotenv-0.0.4.tar.gz (2.0 kB)\n",
            "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/2a/79/933746dc7f4891e5d7de0c113fd3c38cbf76bda0ea1b52df6484e3714928/dotenv-0.0.4.tar.gz#sha256=147fb269f4b65313079c4c2e2c9e74581f1e75c11c92555dcf5b5f48f24599a4 (from https://pypi.org/simple/dotenv/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
            "  Downloading dotenv-0.0.2.tar.gz (6.7 kB)\n",
            "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/ca/41/d922e0b32beaf7251ff1540a4b5a13c54d6bc25ccd9704294524a1f3af17/dotenv-0.0.2.tar.gz#sha256=6a35c7afd2a1584ccfdcd2af22994b125846ded1fa08ef4a831f4e2281303100 (from https://pypi.org/simple/dotenv/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
            "  Downloading dotenv-0.0.1.tar.gz (6.5 kB)\n",
            "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/fa/5a/6dcdddeaa0ddc0bd331fdd1bc8696d9650ede0cb014083716976174eb4b8/dotenv-0.0.1.tar.gz#sha256=04006132a48e301a40b5bc3e8ea0d667a68981f277bb1785af0f8b9f7958e278 (from https://pypi.org/simple/dotenv/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement dotenv (from versions: 0.0.1, 0.0.2, 0.0.4, 0.0.5)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for dotenv\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYoTRcF4tp39"
      },
      "source": [
        "### Importações"
      ],
      "id": "UYoTRcF4tp39"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2e8c01dc",
        "outputId": "5552ce06-7646-4a30-f32e-22706a823287"
      },
      "source": [
        "x# Load EDA Pkgs\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# Load ML Pkgs\n",
        "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('stopwords')\n",
        "nltk.download('rslp')\n",
        "from textblob import TextBlob\n",
        "\n",
        "#charts & others stuff\n",
        "from unidecode import unidecode\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import string\n",
        "from fractions import Fraction\n",
        "import json\n",
        "import os\n",
        "from googletrans import Translator\n",
        "translator = Translator()\n",
        "\n",
        "\n",
        "# from dotenv import load_dotenv\n",
        "# load_dotenv()\n",
        "# load_dotenv('../ibm-credentials.env')\n",
        "\n",
        "# IBM Watson\n",
        "from ibm_watson import NaturalLanguageUnderstandingV1\n",
        "from ibm_watson import LanguageTranslatorV3\n",
        "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n",
        "from ibm_watson.natural_language_understanding_v1  import Features, CategoriesOptions, SentimentOptions\n",
        "\n",
        "\n",
        "\n",
        "# NATURAL_LANGUAGE_UNDERSTANDING_APIKEY = os.environ['NATURAL_LANGUAGE_UNDERSTANDING_APIKEY']\n",
        "# NATURAL_LANGUAGE_UNDERSTANDING_URL    = os.environ['NATURAL_LANGUAGE_UNDERSTANDING_URL']\n",
        "\n",
        "# LANGUAGE_TRANSLATOR_APIKEY = os.environ['LANGUAGE_TRANSLATOR_APIKEY']\n",
        "# LANGUAGE_TRANSLATOR_URL    = os.environ['LANGUAGE_TRANSLATOR_URL']"
      ],
      "id": "2e8c01dc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]   Unzipping stemmers/rslp.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zpFtedfFtSd"
      },
      "source": [
        "## Carrega o Arquivo"
      ],
      "id": "-zpFtedfFtSd"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mNo6sdYFtSe"
      },
      "source": [
        "def RoundSentiment(x):\n",
        "  if x > 0.5:\n",
        "    return 1\n",
        "  elif x < -0.5:\n",
        "    return -1\n",
        "  return 0\n",
        "\n",
        "\n",
        "df_o = pd.read_csv(f\"https://raw.githubusercontent.com/lucianomcsilva/RIWRS/main/tweets_com_ibm_watson_e_ingles.csv\")\n",
        "df_o.drop(df_o.columns[df_o.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)\n",
        "#df[['id_str', 'text', 'screen_name', 'search_term', 'search_term_group', 'source', 'ibm_watson_sentiment', 'ibm_watson_sentiment_label']].sample(10)\n",
        "df = df_o[['id_str', 'text', 'screen_name', 'search_term', 'search_term_group', 'source', 'ibm_watson_sentiment']].loc[df_o['search_term_group'].ne('star+')]\n",
        "df['sentiment'] = df['ibm_watson_sentiment'].apply(lambda x: RoundSentiment(x))"
      ],
      "id": "5mNo6sdYFtSe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YH9COib0Gz_w"
      },
      "source": [
        "# Naive Bayes"
      ],
      "id": "YH9COib0Gz_w"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDlvFJQ4v5Jx"
      },
      "source": [
        "## Prepara uma amostra com 100 registros para validarmos a acuracia por nos mesmos"
      ],
      "id": "SDlvFJQ4v5Jx"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ri6S58wG-st"
      },
      "source": [
        "# Faz uma amostra apenas com 200 registros aleatorios\n",
        "# Iremos descatar alguns que classificarmos como neutro\n",
        "df_nb = df.loc[df['sentiment'].ne(0)].sample(200)\n",
        "\n",
        "#Salva o arquivo para podermos analisar na mao\n",
        "df_nb.to_csv(\"https://raw.githubusercontent.com/lucianomcsilva/RIWRS/main/amostra.csv\")"
      ],
      "id": "2Ri6S58wG-st",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUOMh2bfv5a7"
      },
      "source": [
        "## Carrega o Arquivo Revisado"
      ],
      "id": "QUOMh2bfv5a7"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDrDtB8EvxCt"
      },
      "source": [
        "df_nbr = pd.read_csv('https://raw.githubusercontent.com/lucianomcsilva/RIWRS/main/amostras-revisado.csv', delimiter=';')\n",
        "df_nbr = df_nbr.loc[df_nbr['sentiment_revised'].ne(0)]\n",
        "#df_nbr_pos = df_nbr.loc[df_nbr['sentiment_revised'].eq(1)]\n"
      ],
      "id": "zDrDtB8EvxCt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_nbr"
      ],
      "metadata": {
        "id": "slTPLgwp8ccg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "d0f06b58-5d54-4143-8553-2e6f49baa90d"
      },
      "id": "slTPLgwp8ccg",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Column1       id_str                                               text  \\\n",
              "1       3162  1,45083E+18  Vou ter q assinar o globoplay só pra assistir ...   \n",
              "2       2602  1,45101E+18  PAREM DE ASSISTIR VERDADES SECRETAS O GLOBOPLA...   \n",
              "3       5341  1,45116E+18  enfim vendo death note antes de tirarem da net...   \n",
              "4       7659  1,44949E+18  @nanacaligari @Netflix_Sandman @e3echo @lovegw...   \n",
              "5       5776  1,45087E+18  resmunguei horrores qd anunciaram rebelde da n...   \n",
              "..       ...          ...                                                ...   \n",
              "195     1474  1,44991E+18  @GustavinPlus @Daniel_gutiere Nunca vi! Conto ...   \n",
              "196     8012  1,44957E+18  Assisti Agora Estamos Sozinhos na #PrimeVideo ...   \n",
              "197     3284   1,4524E+18  Como o aplicativo da HBO Max é ruim. Minha nossa!   \n",
              "198     2862  1,45098E+18  O @globoplay de Alguém tá funcionando? #Verdad...   \n",
              "199     1449  1,44996E+18  @Dantinhas Me tornei quem eu mais temiaaa.. pq...   \n",
              "\n",
              "         screen_name search_term search_term_group               source  \\\n",
              "1      Gois99Leticia   globoplay         globoplay   Twitter for iPhone   \n",
              "2            w_petun   globoplay         globoplay   Twitter for iPhone   \n",
              "3       arigoncalvex     netflix           netflix      Twitter Web App   \n",
              "4              n_ins     netflix           netflix   Twitter for iPhone   \n",
              "5            _alinii     netflix           netflix   Twitter for iPhone   \n",
              "..               ...         ...               ...                  ...   \n",
              "195        cinestera     disney+           disney+   Twitter for iPhone   \n",
              "196    crovislimone2  primevideo        primevideo   Twitter for iPhone   \n",
              "197            r0cc0     hbo max            hbomax  Twitter for Android   \n",
              "198      RealityTvBr   globoplay         globoplay  Twitter for Android   \n",
              "199  IFLdesconhecida     disney+           disney+   Twitter for iPhone   \n",
              "\n",
              "    ibm_watson_sentiment  sentiment_revised  sentiment  \n",
              "1           -8,91873E+15                 -1         -1  \n",
              "2           -9,24123E+15                 -1         -1  \n",
              "3           -6,52531E+15                 -1         -1  \n",
              "4                -728079                 -1         -1  \n",
              "5                -760904                 -1         -1  \n",
              "..                   ...                ...        ...  \n",
              "195               899835                 -1          1  \n",
              "196         -9,84106E+15                 -1         -1  \n",
              "197              -911342                 -1         -1  \n",
              "198              -700993                 -1         -1  \n",
              "199              -977784                 -1         -1  \n",
              "\n",
              "[174 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3ee5039d-8f38-4c51-9979-d359b1aa6b4a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Column1</th>\n",
              "      <th>id_str</th>\n",
              "      <th>text</th>\n",
              "      <th>screen_name</th>\n",
              "      <th>search_term</th>\n",
              "      <th>search_term_group</th>\n",
              "      <th>source</th>\n",
              "      <th>ibm_watson_sentiment</th>\n",
              "      <th>sentiment_revised</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3162</td>\n",
              "      <td>1,45083E+18</td>\n",
              "      <td>Vou ter q assinar o globoplay só pra assistir ...</td>\n",
              "      <td>Gois99Leticia</td>\n",
              "      <td>globoplay</td>\n",
              "      <td>globoplay</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>-8,91873E+15</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2602</td>\n",
              "      <td>1,45101E+18</td>\n",
              "      <td>PAREM DE ASSISTIR VERDADES SECRETAS O GLOBOPLA...</td>\n",
              "      <td>w_petun</td>\n",
              "      <td>globoplay</td>\n",
              "      <td>globoplay</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>-9,24123E+15</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5341</td>\n",
              "      <td>1,45116E+18</td>\n",
              "      <td>enfim vendo death note antes de tirarem da net...</td>\n",
              "      <td>arigoncalvex</td>\n",
              "      <td>netflix</td>\n",
              "      <td>netflix</td>\n",
              "      <td>Twitter Web App</td>\n",
              "      <td>-6,52531E+15</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7659</td>\n",
              "      <td>1,44949E+18</td>\n",
              "      <td>@nanacaligari @Netflix_Sandman @e3echo @lovegw...</td>\n",
              "      <td>n_ins</td>\n",
              "      <td>netflix</td>\n",
              "      <td>netflix</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>-728079</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5776</td>\n",
              "      <td>1,45087E+18</td>\n",
              "      <td>resmunguei horrores qd anunciaram rebelde da n...</td>\n",
              "      <td>_alinii</td>\n",
              "      <td>netflix</td>\n",
              "      <td>netflix</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>-760904</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>1474</td>\n",
              "      <td>1,44991E+18</td>\n",
              "      <td>@GustavinPlus @Daniel_gutiere Nunca vi! Conto ...</td>\n",
              "      <td>cinestera</td>\n",
              "      <td>disney+</td>\n",
              "      <td>disney+</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>899835</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>8012</td>\n",
              "      <td>1,44957E+18</td>\n",
              "      <td>Assisti Agora Estamos Sozinhos na #PrimeVideo ...</td>\n",
              "      <td>crovislimone2</td>\n",
              "      <td>primevideo</td>\n",
              "      <td>primevideo</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>-9,84106E+15</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>3284</td>\n",
              "      <td>1,4524E+18</td>\n",
              "      <td>Como o aplicativo da HBO Max é ruim. Minha nossa!</td>\n",
              "      <td>r0cc0</td>\n",
              "      <td>hbo max</td>\n",
              "      <td>hbomax</td>\n",
              "      <td>Twitter for Android</td>\n",
              "      <td>-911342</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>2862</td>\n",
              "      <td>1,45098E+18</td>\n",
              "      <td>O @globoplay de Alguém tá funcionando? #Verdad...</td>\n",
              "      <td>RealityTvBr</td>\n",
              "      <td>globoplay</td>\n",
              "      <td>globoplay</td>\n",
              "      <td>Twitter for Android</td>\n",
              "      <td>-700993</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>1449</td>\n",
              "      <td>1,44996E+18</td>\n",
              "      <td>@Dantinhas Me tornei quem eu mais temiaaa.. pq...</td>\n",
              "      <td>IFLdesconhecida</td>\n",
              "      <td>disney+</td>\n",
              "      <td>disney+</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>-977784</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>174 rows × 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3ee5039d-8f38-4c51-9979-d359b1aa6b4a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3ee5039d-8f38-4c51-9979-d359b1aa6b4a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3ee5039d-8f38-4c51-9979-d359b1aa6b4a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7fYiPwUv4PD"
      },
      "source": [],
      "id": "d7fYiPwUv4PD"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pLauEH0vyrS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ced3b26-d75c-4b90-932b-2ac7aa2ac93f"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn import metrics\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Vectorize the text\n",
        "X = vectorizer.fit_transform(df_nbr['text'])\n",
        "Y = df_nbr['sentiment_revised']\n",
        "\n",
        "# Split dataset\n",
        "x_train,x_test,y_train,y_test = train_test_split(X,Y,test_size=0.33,random_state=42)\n",
        "\n",
        "vocabulary = vectorizer.get_feature_names()\n",
        "dfX = pd.DataFrame(data=X.toarray(), columns=vocabulary) #.iloc[:,0::2]"
      ],
      "id": "3pLauEH0vyrS",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJz5bdwpKjqC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "465a26fa-a884-4d98-be0f-98a065ed5cfa"
      },
      "source": [
        "# Building Our Model\n",
        "clf = MultinomialNB()\n",
        "clf.fit(x_train,y_train)\n",
        "\n",
        "print(\"Accuracy of Model :\",clf.score(x_test,y_test))"
      ],
      "id": "PJz5bdwpKjqC",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of Model : 0.6724137931034483\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_AtjrQFCuF9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebe6e9c3-b252-439e-c6cf-fa8b8f0bd1d5"
      },
      "source": [
        "clf.get_params()"
      ],
      "id": "f_AtjrQFCuF9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'alpha': 1.0, 'class_prior': None, 'fit_prior': True}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZkZJGN49udP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe5f1c7e-5e0c-45ef-bbdb-6ed6edd186ce"
      },
      "source": [
        "test_tweet = ['adorei! recomendo titans.',\n",
        "              'Af pessimo',\n",
        "              'netflix'\n",
        "             ]\n",
        "vect = vectorizer.transform(test_tweet).toarray()\n",
        "vect.shape\n",
        "clf.predict(vect)"
      ],
      "id": "JZkZJGN49udP",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1, -1, -1])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sG0DIKy8_MDt"
      },
      "source": [
        "# class_prob_sorted = clf.feature_log_prob_[0, :].argsort()[::-1]\n",
        "# print(np.take(vectorizer.get_feature_names(), class_prob_sorted[:10]))\n",
        "\n",
        "def get_salient_words(nb_clf, vect, class_ind):\n",
        "    \"\"\"Return salient words for given class\n",
        "    Parameters\n",
        "    ----------\n",
        "    nb_clf : a Naive Bayes classifier (e.g. MultinomialNB, BernoulliNB)\n",
        "    vect : CountVectorizer\n",
        "    class_ind : int\n",
        "    Returns\n",
        "    -------\n",
        "    list\n",
        "        a sorted list of (word, log prob) sorted by log probability in descending order.\n",
        "    \"\"\"\n",
        "\n",
        "    words = vect.get_feature_names_out()\n",
        "    zipped = list(zip(words, nb_clf.feature_log_prob_[class_ind]))\n",
        "    sorted_zip = sorted(zipped, key=lambda t: t[1], reverse=True)\n",
        "\n",
        "    return sorted_zip\n",
        "\n",
        "neg_salient_top_20 = get_salient_words(clf, vectorizer, 0)[:20]\n",
        "pos_salient_top_20 = get_salient_words(clf, vectorizer, 1)[:20]\n",
        "\n"
      ],
      "id": "sG0DIKy8_MDt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yswoaslqAt09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6474668d-cce6-4949-dc11-1137a6fa7b63"
      },
      "source": [
        "neg_salient_top_20"
      ],
      "id": "yswoaslqAt09",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('que', -4.128374310808412),\n",
              " ('co', -4.236587895448645),\n",
              " ('https', -4.265575432321897),\n",
              " ('de', -4.357948752452912),\n",
              " ('netflix', -4.390738575275902),\n",
              " ('não', -4.613882126590113),\n",
              " ('eu', -4.700893503579742),\n",
              " ('disney', -4.796203683384068),\n",
              " ('da', -4.847496977771618),\n",
              " ('globoplay', -4.901564199041894),\n",
              " ('pra', -4.901564199041894),\n",
              " ('na', -5.019347234698277),\n",
              " ('com', -5.083885755835848),\n",
              " ('mas', -5.226986599476522),\n",
              " ('do', -5.489350863944012),\n",
              " ('vai', -5.489350863944012),\n",
              " ('pq', -5.594711379601838),\n",
              " ('um', -5.594711379601838),\n",
              " ('vou', -5.594711379601838),\n",
              " ('por', -5.712494415258222)]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_VH_F7TAw3D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb5860a1-1b22-44bb-8ac3-0a1a57376bbf"
      },
      "source": [
        "pos_salient_top_20"
      ],
      "id": "X_VH_F7TAw3D",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('co', -4.28588277412098),\n",
              " ('https', -4.328442388539775),\n",
              " ('netflix', -4.328442388539775),\n",
              " ('de', -4.824879274853666),\n",
              " ('na', -4.898987247007389),\n",
              " ('que', -4.898987247007389),\n",
              " ('da', -5.066041331670554),\n",
              " ('com', -5.518026455413612),\n",
              " ('globoplay', -5.6721771352408705),\n",
              " ('meu', -5.6721771352408705),\n",
              " ('no', -5.6721771352408705),\n",
              " ('para', -5.6721771352408705),\n",
              " ('tem', -5.6721771352408705),\n",
              " ('as', -5.8544986920348245),\n",
              " ('do', -5.8544986920348245),\n",
              " ('está', -5.8544986920348245),\n",
              " ('eu', -5.8544986920348245),\n",
              " ('hbo', -5.8544986920348245),\n",
              " ('já', -5.8544986920348245),\n",
              " ('os', -5.8544986920348245)]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    }
  ]
}